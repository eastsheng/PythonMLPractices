{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad8b489-1674-4ae4-b8e5-fc3b085ba8df",
   "metadata": {},
   "source": [
    "### 深度卷积神经网络（AlexNet）\n",
    "- 但使用了更多的卷积层和更大的参数空间来拟合大规模数据集ImageNet\n",
    "- 它是浅层神经网络和深度神经网络的分界线\n",
    "- 虽然看上去AlexNet的实现比LeNet的实现也就多了几行代码而已，但这个观念上的转变和真正优秀实验结果的产生令学术界付出了很多年"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d957eff-9e67-4771-b6b6-a3343c94e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bbe107-4d94-4b62-a7b6-bc4bfad0a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f1b237b-e786-4e8a-b542-2db31c506e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=96,kernel_size=11,strides=4,activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=256,kernel_size=5,padding='same',activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4096,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d24cd4-40db-48dd-b263-799a9762338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d output shape\t (1, 54, 54, 96)\n",
      "max_pooling2d output shape\t (1, 26, 26, 96)\n",
      "conv2d_1 output shape\t (1, 26, 26, 256)\n",
      "max_pooling2d_1 output shape\t (1, 12, 12, 256)\n",
      "conv2d_2 output shape\t (1, 12, 12, 384)\n",
      "conv2d_3 output shape\t (1, 12, 12, 384)\n",
      "conv2d_4 output shape\t (1, 12, 12, 256)\n",
      "max_pooling2d_2 output shape\t (1, 5, 5, 256)\n",
      "flatten output shape\t (1, 6400)\n",
      "dense output shape\t (1, 4096)\n",
      "dropout output shape\t (1, 4096)\n",
      "dense_1 output shape\t (1, 4096)\n",
      "dropout_1 output shape\t (1, 4096)\n",
      "dense_2 output shape\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1,224,224,1))\n",
    "for layer in net.layers:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output shape\\t', X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ffe03-dab4-487c-8954-b40a2bd13248",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51bfdd24-3e27-4f28-9638-8d7e7a630786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: (128, 224, 224, 1) y_batch shape: (128,)\n"
     ]
    }
   ],
   "source": [
    "# 将图像高和宽扩大到AlexNet使用的图像高和宽224\n",
    "import numpy as np\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "        (self.train_images, self.train_labels), (self.test_images, self.test_labels) = fashion_mnist.load_data()\n",
    "        self.train_images = np.expand_dims(self.train_images.astype(np.float32)/255.0,axis=-1)\n",
    "        self.test_images = np.expand_dims(self.test_images.astype(np.float32)/255.0,axis=-1)\n",
    "        self.train_labels = self.train_labels.astype(np.int32)\n",
    "        self.test_labels = self.test_labels.astype(np.int32)\n",
    "        self.num_train, self.num_test = self.train_images.shape[0], self.test_images.shape[0]\n",
    "\n",
    "    def get_batch_train(self, batch_size):\n",
    "        index = np.random.randint(0, np.shape(self.train_images)[0], batch_size)\n",
    "        #need to resize images to (224,224)\n",
    "        resized_images = tf.image.resize_with_pad(self.train_images[index],224,224,)\n",
    "        return resized_images.numpy(), self.train_labels[index]\n",
    "\n",
    "    def get_batch_test(self, batch_size):\n",
    "        index = np.random.randint(0, np.shape(self.test_images)[0], batch_size)\n",
    "        #need to resize images to (224,224)\n",
    "        resized_images = tf.image.resize_with_pad(self.test_images[index],224,224,)\n",
    "        return resized_images.numpy(), self.test_labels[index]\n",
    "\n",
    "batch_size = 128\n",
    "dataLoader = DataLoader()\n",
    "x_batch, y_batch = dataLoader.get_batch_train(batch_size)\n",
    "print(\"x_batch shape:\",x_batch.shape,\"y_batch shape:\", y_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f96a35-5427-4348-84a3-19932dab615d",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d56ac5-b34b-497d-b88f-a00321b1aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 850ms/step - loss: 2.3038 - accuracy: 0.1172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f4c92fac6d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_alexnet():\n",
    "    epoch = 5\n",
    "    num_iter = dataLoader.num_train//batch_size\n",
    "    for e in range(epoch):\n",
    "        for n in range(num_iter):\n",
    "            x_batch, y_batch = dataLoader.get_batch_train(batch_size)\n",
    "            net.fit(x_batch, y_batch)\n",
    "            if n%20 == 0:\n",
    "                net.save_weights(\"../data/5.6_alexnet_weights.h5\")\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
    "\n",
    "net.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_batch, y_batch = dataLoader.get_batch_train(batch_size)\n",
    "net.fit(x_batch, y_batch)\n",
    "# train_alexnet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af60f035-47ce-419a-bbf1-bf1dab8b86c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 15s - loss: 1.0256 - accuracy: 0.6020 - 15s/epoch - 232ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0255513191223145, 0.6019999980926514]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_weights(\"../data/5.6_alexnet_weights.h5\")\n",
    "\n",
    "x_test, y_test = dataLoader.get_batch_test(2000)\n",
    "net.evaluate(x_test, y_test, verbose=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
