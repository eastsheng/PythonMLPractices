{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8953b63-b8d8-4838-9d4c-36299b7391d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 10:45:13.480716: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-21 10:45:13.506242: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# 构建模型的3种方法\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm \n",
    "from tensorflow.keras import *\n",
    "\n",
    "\n",
    "train_token_path = \"../data/imdb/train_token.csv\"\n",
    "test_token_path = \"../data/imdb/test_token.csv\"\n",
    "\n",
    "MAX_WORDS = 10000  # We will only consider the top 10,000 words in the dataset\n",
    "MAX_LEN = 200  # We will cut reviews after 200 words\n",
    "BATCH_SIZE = 20 \n",
    "\n",
    "# 构建管道\n",
    "def parse_line(line):\n",
    "    t = tf.strings.split(line,\"\\t\")\n",
    "    label = tf.reshape(tf.cast(tf.strings.to_number(t[0]),tf.int32),(-1,))\n",
    "    features = tf.cast(tf.strings.to_number(tf.strings.split(t[1],\" \")),tf.int32)\n",
    "    return (features,label)\n",
    "\n",
    "ds_train=  tf.data.TextLineDataset(filenames = [train_token_path]) \\\n",
    "   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n",
    "   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "   .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test=  tf.data.TextLineDataset(filenames = [test_token_path]) \\\n",
    "   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n",
    "   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "   .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b43ba064-8559-4f56-950c-8b421ca7f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 7)            70000     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 196, 64)           2304      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 98, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 96, 32)            6176      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 48, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1537      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80017 (312.57 KB)\n",
      "Trainable params: 80017 (312.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 一，Sequential按层顺序创建模型\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n",
    "model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='Nadam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',\"AUC\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee9d300-1b84-4ce3-bb1a-aa0f85c493b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 200)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 200, 7)               70000     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " separable_conv1d (Separabl  (None, 198, 64)              533       ['embedding[0][0]']           \n",
      " eConv1D)                                                                                         \n",
      "                                                                                                  \n",
      " separable_conv1d_2 (Separa  (None, 196, 64)              547       ['embedding[0][0]']           \n",
      " bleConv1D)                                                                                       \n",
      "                                                                                                  \n",
      " separable_conv1d_4 (Separa  (None, 194, 64)              561       ['embedding[0][0]']           \n",
      " bleConv1D)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 66, 64)               0         ['separable_conv1d[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 39, 64)               0         ['separable_conv1d_2[0][0]']  \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 27, 64)               0         ['separable_conv1d_4[0][0]']  \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " separable_conv1d_1 (Separa  (None, 64, 32)               2272      ['max_pooling1d[0][0]']       \n",
      " bleConv1D)                                                                                       \n",
      "                                                                                                  \n",
      " separable_conv1d_3 (Separa  (None, 35, 32)               2400      ['max_pooling1d_1[0][0]']     \n",
      " bleConv1D)                                                                                       \n",
      "                                                                                                  \n",
      " separable_conv1d_5 (Separa  (None, 21, 32)               2528      ['max_pooling1d_2[0][0]']     \n",
      " bleConv1D)                                                                                       \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 32)                   0         ['separable_conv1d_1[0][0]']  \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Gl  (None, 32)                   0         ['separable_conv1d_3[0][0]']  \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Gl  (None, 32)                   0         ['separable_conv1d_5[0][0]']  \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 96)                   0         ['global_max_pooling1d[0][0]',\n",
      "                                                                     'global_max_pooling1d_1[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'global_max_pooling1d_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    97        ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 78938 (308.35 KB)\n",
      "Trainable params: 78938 (308.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 函数式API创建任意结构模型\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=[MAX_LEN])\n",
    "x  = layers.Embedding(MAX_WORDS,7)(inputs)\n",
    "\n",
    "branch1 = layers.SeparableConv1D(64,3,activation=\"relu\")(x)\n",
    "branch1 = layers.MaxPool1D(3)(branch1)\n",
    "branch1 = layers.SeparableConv1D(32,3,activation=\"relu\")(branch1)\n",
    "branch1 = layers.GlobalMaxPool1D()(branch1)\n",
    "\n",
    "branch2 = layers.SeparableConv1D(64,5,activation=\"relu\")(x)\n",
    "branch2 = layers.MaxPool1D(5)(branch2)\n",
    "branch2 = layers.SeparableConv1D(32,5,activation=\"relu\")(branch2)\n",
    "branch2 = layers.GlobalMaxPool1D()(branch2)\n",
    "\n",
    "branch3 = layers.SeparableConv1D(64,7,activation=\"relu\")(x)\n",
    "branch3 = layers.MaxPool1D(7)(branch3)\n",
    "branch3 = layers.SeparableConv1D(32,7,activation=\"relu\")(branch3)\n",
    "branch3 = layers.GlobalMaxPool1D()(branch3)\n",
    "\n",
    "concat = layers.Concatenate()([branch1,branch2,branch3])\n",
    "outputs = layers.Dense(1,activation = \"sigmoid\")(concat)\n",
    "\n",
    "model = models.Model(inputs = inputs,outputs = outputs)\n",
    "\n",
    "model.compile(optimizer='Nadam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',\"AUC\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d17a8727-8dbf-4294-9d3b-b3917b299b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model子类化创建自定义模型\n",
    "# 先自定义一个残差模块，为自定义Layer\n",
    "\n",
    "class ResBlock(layers.Layer):\n",
    "    def __init__(self, kernel_size, **kwargs):\n",
    "        super(ResBlock, self).__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.conv1 = layers.Conv1D(filters=64,kernel_size=self.kernel_size,\n",
    "                                   activation = \"relu\",padding=\"same\")\n",
    "        self.conv2 = layers.Conv1D(filters=32,kernel_size=self.kernel_size,\n",
    "                                   activation = \"relu\",padding=\"same\")\n",
    "        self.conv3 = layers.Conv1D(filters=input_shape[-1],\n",
    "                                   kernel_size=self.kernel_size,activation = \"relu\",padding=\"same\")\n",
    "        self.maxpool = layers.MaxPool1D(2)\n",
    "        super(ResBlock,self).build(input_shape) # 相当于设置self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = layers.Add()([inputs,x])\n",
    "        x = self.maxpool(x)\n",
    "        return x\n",
    "\n",
    "    #如果要让自定义的Layer通过Functional API 组合成模型时可以序列化，需要自定义get_config方法。\n",
    "    def get_config(self):  \n",
    "        config = super(ResBlock, self).get_config()\n",
    "        config.update({'kernel_size': self.kernel_size})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53ba8a6c-3f84-4877-80f7-3a87939313a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 100, 7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试ResBlock\n",
    "resblock = ResBlock(kernel_size = 3)\n",
    "resblock.build(input_shape = (None,200,7))\n",
    "resblock.compute_output_shape(input_shape=(None,200,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c3ac415-e227-4045-8a0f-ef9788dc91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义模型，实际上也可以使用Sequential或者FunctionalAPI\n",
    "\n",
    "class ImdbModel(models.Model):\n",
    "    def __init__(self):\n",
    "        super(ImdbModel, self).__init__()\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.embedding = layers.Embedding(MAX_WORDS,7)\n",
    "        self.block1 = ResBlock(7)\n",
    "        self.block2 = ResBlock(5)\n",
    "        self.dense = layers.Dense(1,activation = \"sigmoid\")\n",
    "        super(ImdbModel,self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dense(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "959b3e2d-78a2-48fe-9b17-ba37765618dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"imdb_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  70000     \n",
      "                                                                 \n",
      " res_block (ResBlock)        multiple                  19143     \n",
      "                                                                 \n",
      " res_block_1 (ResBlock)      multiple                  13703     \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  351       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103197 (403.11 KB)\n",
      "Trainable params: 103197 (403.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = ImdbModel()\n",
    "model.build(input_shape =(None,200))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='Nadam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c91ec0-092d-406c-a0b2-5980312c0aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
