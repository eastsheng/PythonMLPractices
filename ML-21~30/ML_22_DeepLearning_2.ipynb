{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b57ba2-a48b-41de-b590-47bf075222c3",
   "metadata": {},
   "source": [
    "### 多输入通道和多输出通道\n",
    "- 真实数据的维度更高\n",
    "- 例如，彩色图像在高和宽2个维度外还有RGB（红、绿、蓝）3个颜色通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa362b66-3ecc-467c-b113-c676b47f710e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8447b5-4cef-40e1-ab14-bcc534675a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    if len(X.shape) <= 1:\n",
    "        X = tf.reshape(X, (X.shape[0],1))\n",
    "    Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w +1)))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j].assign(tf.cast(tf.reduce_sum(X[i:i+h, j:j+w] * K), dtype=tf.float32))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f30010-2cff-472d-8aa0-cb239ce650bf",
   "metadata": {},
   "source": [
    "#### 1. 多输入通道\n",
    "- 当输入数据含多个通道时，我们需要构造一个输入通道数与输入数据的通道数相同的卷积核，从而能够与含多通道的输入数据做互相关运算。\n",
    "- ![含2个输入通道的二维互相关计算](https://trickygo.github.io/Dive-into-DL-TensorFlow2.0/img/chapter05/5.3_conv_multi_in.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc2009f2-b994-4457-9b8a-3b6f62b34365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现含多个输入通道的互相关运算\n",
    "# 只需要对每个通道做互相关运算，然后进行累加\n",
    "def corr2d_multi_in(X, K):\n",
    "    return tf.reduce_sum([corr2d(X[i], K[i]) for i in range(X.shape[0])],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce60c43-98df-49f7-a89c-2cf11d04ae5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 56.,  72.],\n",
       "       [104., 120.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入\n",
    "X = tf.constant([[[0,1,2],[3,4,5],[6,7,8]],\n",
    "                 [[1,2,3],[4,5,6],[7,8,9]]])\n",
    "# 核\n",
    "K = tf.constant([[[0,1],[2,3]],\n",
    "                 [[1,2],[3,4]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0ead3-e37e-496a-b6b8-457bbf76d52d",
   "metadata": {},
   "source": [
    "#### 2. 多输出通道$c_0$\n",
    "- 当输入通道有多个时，因为我们对各个通道的结果做了累加，所以不论输入通道数是多少，输出通道数总是为1\n",
    "- 如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为$(c_i, k_h, k_w)$的核数组\n",
    "- 将它们在输出通道的维度上连结，卷积核的形状即$(c_0,c_i, k_h, k_w)$\n",
    "- 互相关运算时，每个输出通道上的结果由卷积核在该输出通道上的核数组与整个输入数组计算而来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce1f2c8-fd2c-43d7-ad5d-e3fb6cbc18ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现一个互相关运算函数来计算多个通道的输出\n",
    "def corr2d_multi_in_out(X, K):\n",
    "    # 对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起\n",
    "    return tf.stack([corr2d_multi_in(X, k) for k in K],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a863981-6b04-4938-beab-7e7a6ab09f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将核数组K同K+1（K中每个元素加一）和K+2连结在一起来构造一个输出通道数为3的卷积核\n",
    "K = tf.stack([K, K+1, K+2],axis=0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed82c0b8-33c2-418e-9048-8a0ea99de748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 2, 2), dtype=int32, numpy=\n",
       "array([[[[0, 1],\n",
       "         [2, 3]],\n",
       "\n",
       "        [[1, 2],\n",
       "         [3, 4]]],\n",
       "\n",
       "\n",
       "       [[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[2, 3],\n",
       "         [4, 5]]],\n",
       "\n",
       "\n",
       "       [[[2, 3],\n",
       "         [4, 5]],\n",
       "\n",
       "        [[3, 4],\n",
       "         [5, 6]]]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a52a2223-e7cd-422a-9714-03794a472dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\n",
       "array([[[ 56.,  72.],\n",
       "        [104., 120.]],\n",
       "\n",
       "       [[ 76., 100.],\n",
       "        [148., 172.]],\n",
       "\n",
       "       [[ 96., 128.],\n",
       "        [192., 224.]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4a9a9-1ee7-43fe-a576-bdf236926f7f",
   "metadata": {},
   "source": [
    "#### 3. 1x1 卷积层\n",
    "- 多通道可以拓展卷积层的模型参数\n",
    "- 1×1卷积层通常用来调整网络层之间的通道数，并控制模型复杂度\n",
    "- 主要计算发生在通道维上;\n",
    "- 输入和输出具有相同的高和宽\n",
    "- 输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加\n",
    "- 假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本,那么1x1 卷积层的作用与全连接层等价\n",
    "- ![](https://trickygo.github.io/Dive-into-DL-TensorFlow2.0/img/chapter05/5.3_conv_1x1.svg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c02775-4db0-4173-9985-8d9a5ad0fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用全连接层中的矩阵乘法来实现1×1卷积\n",
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = tf.reshape(X,(c_i, h * w))\n",
    "    K = tf.reshape(K,(c_o, c_i))\n",
    "    Y = tf.matmul(K, X)\n",
    "    return tf.reshape(Y, (c_o, h, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dcd8d6c-1ba7-4af6-9070-00f1e594c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.uniform((3,3,3))\n",
    "K = tf.random.uniform((2,3,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac81dfa-f4c5-4f49-b896-6399ed06930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afa7bb7e-b8cc-4e33-b030-ada7bd109703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.norm(Y1-Y2) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6ef6b-1f9e-4a6b-a5a7-4e668c37b510",
   "metadata": {},
   "source": [
    "### 池化（pooling）层\n",
    "- 为了缓解卷积层对位置的过度敏感性\n",
    "- 同卷积层一样，池化层每次对输入数据的一个固定形状窗口（又称池化窗口）中的元素计算输出\n",
    "- 不同于卷积层里计算输入和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值(最大池化或平均池化)\n",
    "#### 二维最大池化\n",
    "- ![ 池化窗口形状为2×2\n",
    "的最大池化](https://trickygo.github.io/Dive-into-DL-TensorFlow2.0/img/chapter05/5.4_pooling.svg)\n",
    "- 在二维最大池化中，池化窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动;\n",
    "- 当池化窗口滑动到某一位置时，窗口中的输入子数组的最大值即输出数组中相应位置的元素\n",
    "#### 二维平均池化\n",
    "- 工作原理与二维最大池化类似，但将最大运算符替换成平均运算符。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9515ce04-7292-4a22-b874-9091332028c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把池化层的前向计算实现在pool2d函数里\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = tf.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w +1))\n",
    "    Y = tf.Variable(Y)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i,j].assign(tf.reduce_max(X[i:i+p_h, j:j+p_w]))\n",
    "            elif mode =='avg':\n",
    "                Y[i,j].assign(tf.reduce_mean(X[i:i+p_h, j:j+p_w]))\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb841e1f-ee9f-4bfd-9b4b-b1dba02ce8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[4., 5.],\n",
       "       [7., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证二维最大池化层的输出\n",
    "X = tf.constant([[0,1,2],[3,4,5],[6,7,8]],dtype=tf.float32)\n",
    "pool2d(X, (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c130a2c-0b46-48c0-8e75-d9160cf518d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实验二维平均池化层的输出\n",
    "pool2d(X, (2,2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260551ec-af61-4184-a093-1230132f3c85",
   "metadata": {},
   "source": [
    "#### 填充和步幅 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "194db790-e681-46e8-88b2-063e8c109dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4, 1), dtype=int32, numpy=\n",
       "array([[[[ 0],\n",
       "         [ 1],\n",
       "         [ 2],\n",
       "         [ 3]],\n",
       "\n",
       "        [[ 4],\n",
       "         [ 5],\n",
       "         [ 6],\n",
       "         [ 7]],\n",
       "\n",
       "        [[ 8],\n",
       "         [ 9],\n",
       "         [10],\n",
       "         [11]],\n",
       "\n",
       "        [[12],\n",
       "         [13],\n",
       "         [14],\n",
       "         [15]]]], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 池化层填充和步幅与卷积层填充和步幅的工作机制一样\n",
    "#tensorflow default data_format == 'channels_last'\n",
    "#so (1,4,4,1) instead of (1,1,4,4)\n",
    "X = tf.reshape(tf.constant(range(16)), (1,4,4,1))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb78fd15-35fd-4486-8cad-85fa4de4a1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1), dtype=int32, numpy=array([[[[10]]]], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认情况下，MaxPool2D实例里步幅和池化窗口形状相同\n",
    "pool2d = tf.keras.layers.MaxPool2D(pool_size=[3,3])\n",
    "pool2d(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84be504e-f699-4c0a-b10d-707e6bf8335a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 1), dtype=int32, numpy=\n",
       "array([[[[10],\n",
       "         [11]],\n",
       "\n",
       "        [[14],\n",
       "         [15]]]], dtype=int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow 中 padding 有 same 和 valid 两种， same 会在窗口大小不满足时填充0，valid 会舍弃即不填充\n",
    "# one of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input\n",
    "\n",
    "pool2d = tf.keras.layers.MaxPool2D(pool_size=[3,3],padding='same',strides=2)\n",
    "pool2d(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76ddff-31f0-4a23-ae5d-a91df50791a4",
   "metadata": {},
   "source": [
    "#### 多通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bdcf56a-3ecb-4c1b-85a9-125d82c4a028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4, 4, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理多通道输入数据时，池化层对每个输入通道分别池化，\n",
    "# 而不是像卷积层那样将各通道的输入按通道相加\n",
    "# 意味着池化层的输出通道数与输入通道数相等。\n",
    "X = tf.concat([X, X+1], axis=3)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47aea3a1-e344-4d07-9068-e49adeb192f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 2), dtype=int32, numpy=\n",
       "array([[[[10, 11],\n",
       "         [11, 12]],\n",
       "\n",
       "        [[14, 15],\n",
       "         [15, 16]]]], dtype=int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = tf.keras.layers.MaxPool2D(3, padding='same', strides=2)\n",
    "pool2d(X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
