{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cadae470-f66a-4094-b2e4-e5f605729faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 10:56:07.024290: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-21 10:56:07.059833: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-21 10:56:07.061097: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 10:56:07.664922: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# 训练模型的3种方法\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4191c07e-f36b-4418-ab5f-45189eaf5f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#打印时间分割线\n",
    "@tf.function\n",
    "def printbar():\n",
    "    today_ts = tf.timestamp()%(24*60*60)\n",
    "\n",
    "    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n",
    "    minite = tf.cast((today_ts%3600)//60,tf.int32)\n",
    "    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n",
    "\n",
    "    def timeformat(m):\n",
    "        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n",
    "            return(tf.strings.format(\"0{}\",m))\n",
    "        else:\n",
    "            return(tf.strings.format(\"{}\",m))\n",
    "\n",
    "    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n",
    "                timeformat(second)],separator = \":\")\n",
    "    tf.print(\"==========\"*8+timestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bf0906-9292-4c71-b701-13a5b646e431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2110848/2110848 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 10:56:40.051773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-21 10:56:40.076835: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 300\n",
    "BATCH_SIZE = 32\n",
    "(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n",
    "\n",
    "MAX_WORDS = x_train.max()+1\n",
    "CAT_NUM = y_train.max()+1\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n",
    "          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n",
    "          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e297937c-e99f-44e8-8b53-bbe7474c6170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 7)            216874    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 296, 64)           2304      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 148, 64)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 146, 32)           6176      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 73, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2336)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 46)                107502    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332856 (1.27 MB)\n",
      "Trainable params: 332856 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 内置fit方法\n",
    "tf.keras.backend.clear_session()\n",
    "def create_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n",
    "    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n",
    "    return(model)\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer=optimizers.Nadam(),\n",
    "                loss=losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n",
    "    return(model)\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9856656-9ce6-4d5f-a99a-c1a21b434893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "281/281 [==============================] - 4s 9ms/step - loss: 2.0442 - sparse_categorical_accuracy: 0.4591 - sparse_top_k_categorical_accuracy: 0.7432 - val_loss: 1.6790 - val_sparse_categorical_accuracy: 0.5619 - val_sparse_top_k_categorical_accuracy: 0.7609\n",
      "Epoch 2/10\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 1.4708 - sparse_categorical_accuracy: 0.6188 - sparse_top_k_categorical_accuracy: 0.7999 - val_loss: 1.5220 - val_sparse_categorical_accuracy: 0.6122 - val_sparse_top_k_categorical_accuracy: 0.7974\n",
      "Epoch 3/10\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 1.1364 - sparse_categorical_accuracy: 0.7026 - sparse_top_k_categorical_accuracy: 0.8693 - val_loss: 1.5434 - val_sparse_categorical_accuracy: 0.6429 - val_sparse_top_k_categorical_accuracy: 0.8099\n",
      "Epoch 4/10\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 0.8243 - sparse_categorical_accuracy: 0.7872 - sparse_top_k_categorical_accuracy: 0.9254 - val_loss: 1.7655 - val_sparse_categorical_accuracy: 0.6438 - val_sparse_top_k_categorical_accuracy: 0.8117\n",
      "Epoch 5/10\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 0.5812 - sparse_categorical_accuracy: 0.8520 - sparse_top_k_categorical_accuracy: 0.9597 - val_loss: 2.1143 - val_sparse_categorical_accuracy: 0.6318 - val_sparse_top_k_categorical_accuracy: 0.8108\n",
      "Epoch 6/10\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.8942 - sparse_top_k_categorical_accuracy: 0.9793 - val_loss: 2.3848 - val_sparse_categorical_accuracy: 0.6305 - val_sparse_top_k_categorical_accuracy: 0.8143\n",
      "Epoch 7/10\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 0.3436 - sparse_categorical_accuracy: 0.9179 - sparse_top_k_categorical_accuracy: 0.9866 - val_loss: 2.5516 - val_sparse_categorical_accuracy: 0.6269 - val_sparse_top_k_categorical_accuracy: 0.8094\n",
      "Epoch 8/10\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 0.2909 - sparse_categorical_accuracy: 0.9302 - sparse_top_k_categorical_accuracy: 0.9918 - val_loss: 2.7573 - val_sparse_categorical_accuracy: 0.6184 - val_sparse_top_k_categorical_accuracy: 0.8134\n",
      "Epoch 9/10\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 0.2554 - sparse_categorical_accuracy: 0.9367 - sparse_top_k_categorical_accuracy: 0.9941 - val_loss: 2.9702 - val_sparse_categorical_accuracy: 0.6118 - val_sparse_top_k_categorical_accuracy: 0.8161\n",
      "Epoch 10/10\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 0.2291 - sparse_categorical_accuracy: 0.9399 - sparse_top_k_categorical_accuracy: 0.9954 - val_loss: 3.1320 - val_sparse_categorical_accuracy: 0.6104 - val_sparse_top_k_categorical_accuracy: 0.8175\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train,validation_data = ds_test,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce432ef6-f5b3-42cc-809e-74b45977735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 7)            216874    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 296, 64)           2304      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 148, 64)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 146, 32)           6176      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 73, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2336)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 46)                107502    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332856 (1.27 MB)\n",
      "Trainable params: 332856 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 内置train_on_batch方法\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n",
    "    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n",
    "    return(model)\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer=optimizers.Nadam(),\n",
    "                loss=losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n",
    "    return(model)\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab3ad0d-45b3-46db-86ef-9f9f95a64b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,ds_train,ds_valid,epoches):\n",
    "\n",
    "    for epoch in tf.range(1,epoches+1):\n",
    "        model.reset_metrics()\n",
    "\n",
    "        # 在后期降低学习率\n",
    "        if epoch == 5:\n",
    "            model.optimizer.lr.assign(model.optimizer.lr/2.0)\n",
    "            tf.print(\"Lowering optimizer Learning Rate...\\n\\n\")\n",
    "\n",
    "        for x, y in ds_train:\n",
    "            train_result = model.train_on_batch(x, y)\n",
    "\n",
    "        for x, y in ds_valid:\n",
    "            valid_result = model.test_on_batch(x, y,reset_metrics=False)\n",
    "\n",
    "        if epoch%1 ==0:\n",
    "            printbar()\n",
    "            tf.print(\"epoch = \",epoch)\n",
    "            print(\"train:\",dict(zip(model.metrics_names,train_result)))\n",
    "            print(\"valid:\",dict(zip(model.metrics_names,valid_result)))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5116b9c6-f984-45c5-9bc5-bc1bae6c3128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================10:59:16\n",
      "epoch =  1\n",
      "train: {'loss': 1.3382827043533325, 'sparse_categorical_accuracy': 0.6363636255264282, 'sparse_top_k_categorical_accuracy': 0.8181818127632141}\n",
      "valid: {'loss': 1.6594516038894653, 'sparse_categorical_accuracy': 0.5665785074234009, 'sparse_top_k_categorical_accuracy': 0.766313910484314}\n",
      "\n",
      "================================================================================10:59:20\n",
      "epoch =  2\n",
      "train: {'loss': 0.8737804889678955, 'sparse_categorical_accuracy': 0.7727272510528564, 'sparse_top_k_categorical_accuracy': 0.9090909361839294}\n",
      "valid: {'loss': 1.5068058967590332, 'sparse_categorical_accuracy': 0.6190476417541504, 'sparse_top_k_categorical_accuracy': 0.7989417910575867}\n",
      "\n",
      "================================================================================10:59:24\n",
      "epoch =  3\n",
      "train: {'loss': 0.5218415856361389, 'sparse_categorical_accuracy': 0.8636363744735718, 'sparse_top_k_categorical_accuracy': 0.9545454382896423}\n",
      "valid: {'loss': 1.553186058998108, 'sparse_categorical_accuracy': 0.630511462688446, 'sparse_top_k_categorical_accuracy': 0.8139329552650452}\n",
      "\n",
      "================================================================================10:59:28\n",
      "epoch =  4\n",
      "train: {'loss': 0.2734069526195526, 'sparse_categorical_accuracy': 0.8636363744735718, 'sparse_top_k_categorical_accuracy': 1.0}\n",
      "valid: {'loss': 1.7776180505752563, 'sparse_categorical_accuracy': 0.6300705671310425, 'sparse_top_k_categorical_accuracy': 0.803791880607605}\n",
      "\n",
      "Lowering optimizer Learning Rate...\n",
      "\n",
      "\n",
      "================================================================================10:59:33\n",
      "epoch =  5\n",
      "train: {'loss': 0.14766894280910492, 'sparse_categorical_accuracy': 0.9545454382896423, 'sparse_top_k_categorical_accuracy': 1.0}\n",
      "valid: {'loss': 2.06892728805542, 'sparse_categorical_accuracy': 0.6344797015190125, 'sparse_top_k_categorical_accuracy': 0.8046737313270569}\n",
      "\n",
      "================================================================================10:59:37\n",
      "epoch =  6\n",
      "train: {'loss': 0.11239803582429886, 'sparse_categorical_accuracy': 0.9545454382896423, 'sparse_top_k_categorical_accuracy': 1.0}\n",
      "valid: {'loss': 2.2685258388519287, 'sparse_categorical_accuracy': 0.631393313407898, 'sparse_top_k_categorical_accuracy': 0.8024691343307495}\n",
      "\n",
      "================================================================================10:59:41\n",
      "epoch =  7\n",
      "train: {'loss': 0.10373079776763916, 'sparse_categorical_accuracy': 0.9545454382896423, 'sparse_top_k_categorical_accuracy': 1.0}\n",
      "valid: {'loss': 2.461953639984131, 'sparse_categorical_accuracy': 0.6278659701347351, 'sparse_top_k_categorical_accuracy': 0.8095238208770752}\n",
      "\n",
      "================================================================================10:59:44\n",
      "epoch =  8\n",
      "train: {'loss': 0.08776237815618515, 'sparse_categorical_accuracy': 0.9545454382896423, 'sparse_top_k_categorical_accuracy': 1.0}\n",
      "valid: {'loss': 2.6282167434692383, 'sparse_categorical_accuracy': 0.6261022686958313, 'sparse_top_k_categorical_accuracy': 0.8068783283233643}\n",
      "\n",
      "================================================================================10:59:48\n",
      "epoch =  9\n",
      "train: {'loss': 0.0862463042140007, 'sparse_categorical_accuracy': 0.9545454382896423, 'sparse_top_k_categorical_accuracy': 1.0}\n",
      "valid: {'loss': 2.7724881172180176, 'sparse_categorical_accuracy': 0.628747820854187, 'sparse_top_k_categorical_accuracy': 0.8051146268844604}\n",
      "\n",
      "================================================================================10:59:52\n",
      "epoch =  10\n",
      "train: {'loss': 0.0816488191485405, 'sparse_categorical_accuracy': 0.9545454382896423, 'sparse_top_k_categorical_accuracy': 1.0}\n",
      "valid: {'loss': 2.9003045558929443, 'sparse_categorical_accuracy': 0.628747820854187, 'sparse_top_k_categorical_accuracy': 0.8068783283233643}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model,ds_train,ds_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c20129-9491-4b2c-9f06-79bfb5a3f036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 7)            216874    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 296, 64)           2304      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 148, 64)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 146, 32)           6176      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 73, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2336)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 46)                107502    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332856 (1.27 MB)\n",
      "Trainable params: 332856 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 自定义训练循环\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n",
    "    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n",
    "    return(model)\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a408a1d3-5e3e-42cb-a5ca-d23796eb7f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================11:00:24\n",
      "Epoch=1,Loss:2.00272822,Accuracy:0.474727243,Valid Loss:1.64700532,Valid Accuracy:0.579697251\n",
      "\n",
      "================================================================================11:00:26\n",
      "Epoch=2,Loss:1.4377737,Accuracy:0.632264555,Valid Loss:1.51856732,Valid Accuracy:0.621994674\n",
      "\n",
      "================================================================================11:00:28\n",
      "Epoch=3,Loss:1.130481,Accuracy:0.704186141,Valid Loss:1.57685363,Valid Accuracy:0.638468385\n",
      "\n",
      "================================================================================11:00:31\n",
      "Epoch=4,Loss:0.842117965,Accuracy:0.778111756,Valid Loss:1.86095572,Valid Accuracy:0.63089937\n",
      "\n",
      "================================================================================11:00:33\n",
      "Epoch=5,Loss:0.613242865,Accuracy:0.843576,Valid Loss:2.25635076,Valid Accuracy:0.621104181\n",
      "\n",
      "================================================================================11:00:36\n",
      "Epoch=6,Loss:0.461236119,Accuracy:0.884324193,Valid Loss:2.58688688,Valid Accuracy:0.613535166\n",
      "\n",
      "================================================================================11:00:38\n",
      "Epoch=7,Loss:0.371550143,Accuracy:0.909151614,Valid Loss:2.76659656,Valid Accuracy:0.614870906\n",
      "\n",
      "================================================================================11:00:40\n",
      "Epoch=8,Loss:0.312922657,Accuracy:0.923847675,Valid Loss:2.99696064,Valid Accuracy:0.607301891\n",
      "\n",
      "================================================================================11:00:42\n",
      "Epoch=9,Loss:0.273430437,Accuracy:0.932420373,Valid Loss:3.30156302,Valid Accuracy:0.606856644\n",
      "\n",
      "================================================================================11:00:45\n",
      "Epoch=10,Loss:0.245311394,Accuracy:0.937653065,Valid Loss:3.55977201,Valid Accuracy:0.610418499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Nadam()\n",
    "loss_func = losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_loss = metrics.Mean(name='train_loss')\n",
    "train_metric = metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "valid_loss = metrics.Mean(name='valid_loss')\n",
    "valid_metric = metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features,training = True)\n",
    "        loss = loss_func(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss.update_state(loss)\n",
    "    train_metric.update_state(labels, predictions)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def valid_step(model, features, labels):\n",
    "    predictions = model(features)\n",
    "    batch_loss = loss_func(labels, predictions)\n",
    "    valid_loss.update_state(batch_loss)\n",
    "    valid_metric.update_state(labels, predictions)\n",
    "\n",
    "\n",
    "def train_model(model,ds_train,ds_valid,epochs):\n",
    "    for epoch in tf.range(1,epochs+1):\n",
    "\n",
    "        for features, labels in ds_train:\n",
    "            train_step(model,features,labels)\n",
    "\n",
    "        for features, labels in ds_valid:\n",
    "            valid_step(model,features,labels)\n",
    "\n",
    "        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}'\n",
    "\n",
    "        if epoch%1 ==0:\n",
    "            printbar()\n",
    "            tf.print(tf.strings.format(logs,\n",
    "            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n",
    "            tf.print(\"\")\n",
    "\n",
    "        train_loss.reset_states()\n",
    "        valid_loss.reset_states()\n",
    "        train_metric.reset_states()\n",
    "        valid_metric.reset_states()\n",
    "\n",
    "train_model(model,ds_train,ds_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca5c1c2-ede7-4d37-9b92-0dee2e3a0438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "gpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
